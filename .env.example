# MemoroseDB Environment Configuration Template
# Copy this file to .env and fill in your actual values.

# ------------------------------------------------------------------------------
# LLM Provider Configuration
# ------------------------------------------------------------------------------

# LLM Provider: "gemini" (default) or "openai"
LLM_PROVIDER=gemini

# Google Gemini Configuration
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# OpenAI Configuration (Optional, if LLM_PROVIDER=openai)
# OPENAI_API_KEY=your_openai_api_key_here

# ------------------------------------------------------------------------------
# Model Selection
# ------------------------------------------------------------------------------

# LLM Model (Used for semantic compression and insight synthesis)
# For Gemini: gemini-2.0-flash, gemini-2.5-flash, gemini-2.5-pro
# For OpenAI: gpt-4o, gpt-4o-mini
LLM_MODEL=gemini-2.0-flash

# Embedding Model (Used for vector search)
# For Gemini: text-embedding-004
# For OpenAI: text-embedding-3-small, text-embedding-3-large
EMBEDDING_MODEL=text-embedding-004

# ------------------------------------------------------------------------------
# Server & Network Settings
# ------------------------------------------------------------------------------

# Logging level: error, warn, info, debug, trace
RUST_LOG=info

# Gateway: Number of storage shards to route between
SHARD_COUNT=2

# Gateway: Prefix for node URLs (e.g. http://localhost- for http://localhost-0, http://localhost-1)
NODE_PREFIX=http://127.0.0.1-
